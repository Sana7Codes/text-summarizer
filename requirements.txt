# Core ML + Transformers
transformers==4.41.2
torch>=1.12
accelerate==0.30.1
sentencepiece==0.2.0 

# Inference pipeline
scikit-learn>=1.0.2
numpy>=1.21.0
pandas>=1.3.0

# Serving via API
fastapi==0.111.0
uvicorn[standard]==0.30.1

# Hugging Face model & tokenizer loading
huggingface-hub==0.23.2
tokenizers==0.19.1

# Logging + configuration
pyyaml>=6.0.1
loguru>=0.7.2

# File utilities (optional if you use AWS)
boto3>=1.34.0

# Safe async (used by FastAPI/Uvicorn)
aiohttp==3.9.5
